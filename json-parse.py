#!/usr/bin/env python3

import sys
import json
import os
import elasticsearch
import elasticsearch.helpers
from elasticsearch import Elasticsearch

import tensorflow as tf
import tensorflow_hub as thub
import numpy as np

if 'ESURL' not in os.environ:
    es_url = "http://localhost:9200"
else:
    es_url = os.environ['ESURL']

es = Elasticsearch([es_url])

UNIVERSAL_SENTENCE_ENCODER_URL = 'https://tfhub.dev/google/universal-sentence-encoder/4'

# Configure tensorflow
# TODO: detect and use any compatible GPUs
tf.get_logger().setLevel('INFO')
tf.config.threading.set_inter_op_parallelism_threads(6)
tf.config.threading.set_intra_op_parallelism_threads(6)

embed = thub.load(UNIVERSAL_SENTENCE_ENCODER_URL)

class CVE:

    def __init__(self):
        self.ids = []
        self.current = -1
        self.rh_data = None        

    def add(self, i):
        cve = i['cve']
        cve_id = cve['CVE_data_meta']['ID']
        # some of these don't exist, just give up if it fails
        if 'impact' in i:
            cve['impact'] = i['impact']
        if 'configurations' in i:
            cve['configurations'] = i['configurations']
        if 'publishedDate' in i:
            cve['publishedDate'] = i['publishedDate']
        if 'lastModifiedDate' in i:
            cve['lastModifiedDate'] = i['lastModifiedDate']
        cve['year'] = cve_id.split('-')[1]
        cve['just_id'] = cve_id.split('-')[2]

        rh_data = self.__get_redhat_data(cve_id)
        if 'cvss3' in rh_data:
            cve['rh_cvssv3'] = rh_data['cvss3']
        if 'cvss2' in rh_data:
            cve['rh_cvssv2'] = rh_data['cvss2']
        if 'impact' in rh_data:
            cve['rh_impact'] = rh_data['impact']

        # Generate text embeddings for CVE description
        # description
        #   |_ [description_data]
        #       |_ [0]
        #           |_ lang
        #           |_ text
        #           |_ embeddings vector
        description_data = cve['description']['description_data'][0]
        if description_data['lang'] == 'en':
            embeddings = embed([description_data['value']])

            # Convert to a format that elasticsearch can serialize
            vector = np.array(embeddings.numpy())
            cve['description']['description_data'][0]['vector'] = vector.tolist()[0]

        cve_bulk = {
                    "_op_type": "update",
                    "_index":   "cve-index",
                    "_id":      cve_id,
                    "doc_as_upsert": True,
                    "doc":  cve
                   }

        self.ids.append(cve_bulk)

    def __next__(self):
        "Handle a call to next()"

        self.current = self.current + 1
        if self.current >= len(self.ids):
            raise StopIteration

        return self.ids[self.current]

    def __iter__(self):
        return self

    def __len__(self):
        return len(self.ids)

    def __get_redhat_data(self, the_cve):

        if self.rh_data is None:

            self.rh_data = {}

            fh = open('data/cve_dates.txt')
            for line in fh.readlines():
                line = line.rstrip()

                # The data format looks like
                # CVE key=value,key=value,...
                split_line = line.split(' ')
                cve = split_line[0]
                self.rh_data[cve] = {}

                if len(split_line) > 1:
                    # There are a few CVE IDs that don't have any data
                    data = split_line[1]
                else:
                    next

                for keyval in data.split(','):
                    (key, value) = keyval.split('=')
                    if key == 'cvss3' or key == 'cvss2':
                        # The cvss scores are special, we only want the
                        # number
                        value = float(value.split('/')[0])
                    self.rh_data[cve][key] = value

        if the_cve in self.rh_data:
            return self.rh_data[the_cve]
        else:
            return {}

def main():

    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    else:
        print("Usage: %s <nvd-xml-file>" % (sys.argv[0]))
        sys.exit(1)

    # First let's see if the index exists
    if es.indices.exists('cve-index') is False:
        # We have to create it and add a mapping
        fh = open('cve-index-json-mapping.json')
        mapping = json.load(fh)
        es.indices.create('cve-index', body=mapping)

    fh = open(input_file)
    json_data = json.load(fh)

    the_cves = CVE()
    for i in json_data['CVE_Items']:

        # ['CVE_Items'][0]['cve']['CVE_data_meta']['ID']
        the_cves.add(i)
        #es.update(id=cve_id, index="cve-index", body={'doc' : cve, 'doc_as_upsert': True})


    for ok, item in elasticsearch.helpers.streaming_bulk(es, the_cves, max_retries=2):
            if not ok:
                print("ERROR:")
                print(item)

if __name__ == "__main__":
    main()

