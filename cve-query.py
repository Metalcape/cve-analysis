#!/usr/bin/env python3

import os

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow logging

import elasticsearch
import argparse
import tensorflow as tf
import tensorflow_hub as thub
import numpy as np
from prettytable import PrettyTable, prettytable

# Elasticsearch settings
if 'ESURL' not in os.environ:
    es_url = "http://localhost:9200"
else:
    es_url = os.environ['ESURL']
es = elasticsearch.Elasticsearch([es_url], timeout=300)

UNIVERSAL_SENTENCE_ENCODER_URL = 'https://tfhub.dev/google/universal-sentence-encoder/4'
CVE_INDEX = 'cve-index'
ARTICLE_INDEX = 'crawl_sec'
MAX_HITS = 10
WRAP_LIMIT = 30

ARTICLE_SUBSET = {
    "bool": {
        "must_not": {
            "match": {
                "website": "https://packetstormsecurity.com"
            }
        }
    }
}

parser = argparse.ArgumentParser(
    description='Find CVEs and cybersecurity articles using text similarity in Elasticsearch. '
    'CVEs are taken from the \'cve-index\' index, and cybersecurity articles are taken from the '
    '\'crawl_sec\' index in Elasticsearch (default ES host: either $ESURL or localhost:9200).'
)
parser.add_argument('-r', '--relevant', metavar='CVE-ID', type=str, help='Find relevant articles given a CVE')
parser.add_argument('-c', '--cve-search', metavar='desc', type=str, help='Find CVEs given a description')
parser.add_argument('-a', '--article-search', metavar='desc', type=str, help='Find articles given a description')

def main():
    args = parser.parse_args()
    if args.relevant:
        find_article_by_cve(args.relevant)
    elif args.cve_search:
        find_cve(args.cve_search)
    elif args.article_search:
        find_article(args.article_search)
    else:
        parser.print_help()

def find_article_by_cve(cve):
    cve_query = {
        "match": {
            "_id": str.upper(cve)
        }
    }

    response = es_query(CVE_INDEX, cve_query, 'description.description_data')
    if response['hits']['total']['value'] == 0:
        print("No hits found when searching for '{0}'".format(cve))
        exit()
    desc_data = response['hits']['hits'][0]['_source']['description']['description_data'][0]
    print('\nCVE description:')
    print('"{0}"\n'.format(desc_data['value']))

    script_query = {
        "script_score": {
            "query": ARTICLE_SUBSET,
            "script": {
                "source": "cosineSimilarity(params.query_vector, 'title_vector') + 1.0",
                "params": {
                    "query_vector": desc_data['vector']
                }
            }
        }
    }

    response = es_query(ARTICLE_INDEX, script_query, ['id', 'title', 'website'])
    rows = [
        ['Title', 'URL', 'Similarity score']
    ]
    for hit in response['hits']['hits']:
        rows.append([hit['_source']['title'], hit['_source']['id'],  round(hit['_score'] - 1, 5)])
    print_result(rows)

def find_cve(desc):
    desc_vector = generate_vector(desc)
    query = {
        "script_score": {
            "query": {
                "match_all": {}
            },
            "script": {
                "source": "cosineSimilarity(params.query_vector, 'description.description_data.vector') + 1.0",
                "params": {
                    "query_vector": desc_vector
                }
            }
        }
    }

    response = es_query(CVE_INDEX, query, ['_id', 'description.description_data.value'])
    rows = [['CVE','Description', 'Score']]
    for hit in response['hits']['hits']:
        rows.append([hit['_id'], hit['_source']['description']['description_data'][0]['value'],  round(hit['_score'] - 1, 5)])
    print_result(rows)

def find_article(desc):
    desc_vector = generate_vector(desc)
    query = {
        "script_score": {
            "query": ARTICLE_SUBSET,
            "script": {
                "source": "cosineSimilarity(params.query_vector, 'title_vector') + 1.0",
                "params": {
                    "query_vector": desc_vector
                }
            }
        }
    }

    response = es_query(ARTICLE_INDEX, query, ['title', 'id'])
    rows = [['Title','URL', 'Similarity score']]
    for hit in response['hits']['hits']:
        rows.append([hit['_source']['title'], hit['_source']['id'], round(hit['_score'] - 1, 5)])
    print_result(rows)

def print_result(rows):
    tab = PrettyTable(rows[0])
    tab.set_style(prettytable.PLAIN_COLUMNS)
    tab.align = 'l'
    for row in rows[1:]:
        tab.add_row(row)
    print(tab)

def generate_vector(text):
    # Tensorflow settings
    gpus = tf.config.list_physical_devices('GPU')
    if len(gpus) > 0:
        # Configure GPU and limit memory
        tf.config.set_logical_device_configuration(
            gpus[0],
            [tf.config.LogicalDeviceConfiguration(memory_limit=2048)])
        logical_gpus = tf.config.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
    else:
        # Thread limit when running on CPU
        tf.config.threading.set_inter_op_parallelism_threads(6)
        tf.config.threading.set_intra_op_parallelism_threads(6)
    
    embed = thub.load(UNIVERSAL_SENTENCE_ENCODER_URL)
    tensor = embed([text])
    vector = np.array(tensor.numpy())
    return vector.tolist()[0]

def es_query(index, query, fields):
    response = es.search(
        index=index,
        body={
            "query": query,
            "_source": {
                "includes": fields
            },
            "size": MAX_HITS
        }
    )
    return response

if __name__ == '__main__':
    main()